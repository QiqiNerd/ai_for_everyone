# Week 1 – Lesson 2: What Is Machine Learning?

Machine learning is the most important technology driving the current rise of AI.

This lesson helps you understand what it is and how it might apply to your company or industry.

## 1. What Does Machine Learning Do?
At its core, machine learning learns A → B mappings — from input A to output B.

This most common form of ML is called Supervised Learning（监督学习）.

## 2. Supervised Learning: Input → Output Examples
|Input (A) |	Output (B) |	Application|
| :------: | :------: | :------:|
| Email text	| Spam (1) or Not Spam (0)| 	Spam detection（垃圾邮件过滤）
| Audio clip| 	Transcript (written text)| 	Speech recognition（语音识别）
| English sentence|	Chinese/Spanish/etc.| 	Machine translation（机器翻译）
| Ad info + User info	| Will you click (1/0)?	| Online advertising（在线广告）
| Camera + radar data| 	Position of cars	|Self-driving cars（自动驾驶）
| Image of a product	| Is there a defect?	| Visual inspection in manufacturing（制造业的视觉检测）

- Even if the A → B format sounds simple, the right use case can deliver huge business value.

- Why Online Ads Are So Profitable
  - AI systems learn which ads you're most likely to click based on personal and ad data.
  - Though not emotionally inspiring, this drives billions in revenue and is one of the most lucrative AI applications today.

## 3. Supervised Learning in Generative AI
- Generative AI (生成式人工智能) systems like ChatGPT are built on supervised learning too.

- They learn from huge text datasets (hundreds of billions of words).

- Their job: predict the next word given some initial input text (prompt).

## 4. How LLMs (大语言模型) Learn
- Example sentence: “My favorite drink is lychee bubble tea.”

- ML breaks this into smaller A → B examples:

  - Input: “My favorite drink” → Output: “is”

  - Input: “My favorite drink is” → Output: “lychee”

  - Input: “My favorite drink is lychee” → Output: “bubble”


- By learning from billions of such sequences, the model can generate fluent and relevant new text.
- This explanation skips advanced steps like:

  - How LLMs follow instructions (not just predict random next words)

  - How developers reduce toxic, biased, or harmful outputs



## 5. Why Is Supervised Learning Taking Off Now?

- Key Historical Shift: More Data + Better Models
A Simple Graph Andrew Ng Uses:

- Traditional AI:
With more data, performance improved a little, then plateaued (性能提升不大).

- Modern AI with Neural Networks (神经网络) and Deep Learning (深度学习):
Performance keeps improving steadily with more data.

- Bigger neural networks = better results (if trained on enough data).

|Neural Network Size|	Performance Curve|
|:---:|:---|
|Small NN|	Improves slowly|
Medium NN	|Improves more|
Large NN	|Keeps improving significantly with more data|

- Why This Matters:
  - With enough data + powerful models: Better speech recognition; More effective online ads; More reliable self-driving cars

- These improvements made AI products more usable, more valuable, and more widely adopted.

## 6. What Do You Need for Great AI Performance?
1. Lots of Data

   - “Big Data”（大数据）helps machine learning systems improve.

   - Internet & digital records made data widely available.

2. Large Neural Networks

   Enabled by:

   - Faster processors, especially GPUs（图形处理器）

   - Moore’s Law (摩尔定律：芯片性能逐年提升)

   - Cloud computing and hardware advances

Now even non-tech companies can train large neural nets and get solid results.


## 7. Generative AI Breakthroughs
- Large models + large datasets enabled recent LLM breakthroughs.

- This same scaling strategy powered systems like ChatGPT.

## Summary: Why Supervised Learning Matters
- It is the foundation of most AI systems today.

- Learns input → output mappings.

- With the right data and model, this simple setup can transform entire industries.

